> https://www.zhihu.com/question/29619212/answer/139962780





根据人们对过拟合的理解不同，答案也不同。这里不谈过拟合的原因，仅谈我理解的过拟合的表现：训练集上表现优秀，测试集上表现欠佳；换通俗的话说，已见过的题目会解答，未见过的题目解不开。

不同意上述对过拟合描述的朋友不需要往下看了。

**语音：**

* 听不懂其他地区人的同国话：

 **a.** 音调/顿挫：排除词汇不同的情况，即便是相同词汇，很多人听不懂大连话的抑扬顿挫。同样现象的有日本的大阪弁，印度和新西兰等英语。

 **b.** 音节：同样的发音，在某些人的口中会有些许不同。内容相同时，很多人会听不懂老年人和小孩的发音。

 **c.** 噪音：透过对讲机的话，无法听清从未遇到过的噪音环境的对话。


> 这些现象的共性都是大家熟悉（表现良好）旧环境（已见的训练样本），而不适应（表现不佳）新环境（未见的测试样本）所造成的。例子中造成“过拟合”的具体原因会有不同。

* 其他原因造成的声音会被识别成“合理的声音”

 **a.** 有个被洗澡的猫的叫声就被中国人识别成了“巧克力”

 **b.** 外语的很多音会被中国人识别成中文音，中文注音W（打不溜）


> 这类现象是脑中的神经元的组合只为完成对中文的识别即可，而这种组合有无数种，构建出还能顾及外语音节的神经元方式的可能性较低。

  
其他例子

**画面：**

 **1.** 看不懂别人的字体，只能看懂“规整”的字体

 **2.** 这张海豚图对曾经纯真的我来说越来越模糊了

![](https://picx.zhimg.com/50/v2-c214fba8ea30fba035b5bded9cbcaf85_720w.jpg?source=2c26e567)

  
**题海：**只会做已经做过的题，而不会做没见过的题。高考前的题海战术就是在抑制过拟合。

**施工：**在熟悉的厨房做饭好吃，。。。

生物学系和机器学习的方式不同，但目的是相同的。

两者都是从有限的数据中找到可以解释该数据的映射f，并且再次使用。

只要数据是有限的，那么过拟合就无法避免。但反过来，如果可以获得所有数据，用无限大的查找表就能完美表示该映射，这同时失去了学习的意义。


> 因为学习就是要从有限的数据中获得较好的f。

过拟合是无法被完全消除的，只能被抑制。大家所说的防止过拟合往往也都是指抑制过拟合。

机器学习和人类学习虽然**实现方式不同**，但**要达成的目的类似**。

机器学习所面临的问题，人类学习同样面对。

不过大脑有非常好的克服机制。可以尝试比较一下：

神经网络抑制过拟合有以下常用的几点，而这几点在人们日常学习中同样适用。


> 拿平时做题为训练集，高考为测试集来说。

1. dropout（遗忘），细节有时也能形成规律，但不会每次都形成。遗忘可以去掉那些偶然形成的细节规律，提高普遍性。
2. shuffle（乱序），训练的样本不要有固定顺序，而要随机打乱，同样可以抑制偶然形成的细节规律。比如不要一直从abandon开始背单词一样。
3. L2 regularization（保持最简化），解决的方案不要过于复杂。不然只能顾及特例而失去普遍性。
4. mini-batch（多题一起做），相互比较后得出结论。比如同时看两本描述不同的书可以得到更好地理解。
5. noisy layer（加噪音），题目加入一些干扰项、改变考前环境、教室、平时状态等。

又如下图中对于**是否有教师指到的问题上**比较人类学习和深层学习对应的类似点。

 a. 人类若有老师，当将问题想偏或想复杂时，老师可以提醒你；当深层学习找出的解过于复杂时，L2 regularization会产生较高的惩罚。

 b. 人类若有老师，可以不用从零开始学习，而知道从哪里开始；当深层学习预训练时，同样可以找到一个较好的起点来避开局部极小值或鞍点。

![](https://picx.zhimg.com/50/v2-c06c2bf088669764517d5c1c7a66d085_720w.jpg?source=2c26e567)

**说深层学习和人脑中的神经网络不相同，相当于是说计算机在算乘法和人类大脑在算乘法时不相同。二者的实现方式当然不同。当关注点不该在此，而要考虑如何彼此借鉴和指导。**

  
谷歌的deep mind难道是觉得好玩才研究deep dream吗？背后的逻辑更可能是既然做梦被自然选择留下来，就或许有其潜在的对学习有利的作用在其中。

**题外话：**

学习是为了再次使用，而再次使用的场景往往会比被学习所用到的内容大无数倍。学习同时也是一个动态过程，因为应用的场景也会随时间和需求改变。

这种改变是对于智能而言非常重要的能力之一。人类在这方面做的就比较好。

但对于目前的机器学习而言，这种改变往往意味着重新训练一个神经网络，但这样好时巨大，以前学过的内容全部都白费了。很多研究都是努力解决该问题。这是机器学习正在不断努力的方向，也同时是想要超越人类的地方。因为“调节”能力对于人脑而言同样非常困难。想想成人从中文学习英语的过程。




